import numpy as np
import pandas as pd
from sklearn.metrics import accuracy_score
from scipy.stats import mode
from scipy.spatial.distance import cosine, jaccard
from sklearn.metrics.pairwise import euclidean_distances


class KMeans:
    def __init__(self, n_clusters=3, max_iterations=100, tol=0.00001, distance_metric='euclidean'):
        self.n_clusters = n_clusters
        self.max_iterations = max_iterations
        self.tol = tol
        self.distance_metric = distance_metric
        self.number_of_iterations = 0

    def initialize_centroids(self, X):
        if isinstance(X, pd.DataFrame):
            indices = np.random.choice(X.index, self.n_clusters, replace=False)
            return X.loc[indices, :].values
        else:
            indices = np.random.choice(X.shape[0], self.n_clusters, replace=False)
            return X[indices, :]

    def compute_distance(self, x, centroid):
        if self.distance_metric == 'euclidean':
            return self.euclidean_distance(x, centroid)
        elif self.distance_metric == 'cosine':
            return 1 - self.cosine_similarity(x, centroid)
        elif self.distance_metric == 'jaccard':
            return 1 - self.jaccard_similarity(x, centroid)

    def euclidean_distance(self, x, y):
        return np.linalg.norm(x - y)

    def cosine_similarity(self, x, y):
        dot_product = np.dot(x, y)
        norm_x = np.linalg.norm(x)
        norm_y = np.linalg.norm(y)
        return dot_product / (norm_x * norm_y)

    def jaccard_similarity(self, x, y):
        intersection = np.sum(np.minimum(x, y))
        union = np.sum(np.maximum(x, y))
        return intersection / union if union != 0 else 0

    def assign_clusters(self, X, centroids):
        distances = euclidean_distances(X, centroids)
        return np.argmin(distances, axis=1)

    def update_centroids(self, X, labels):
        centroids = np.zeros((self.n_clusters, X.shape[1]))
        for i in range(self.n_clusters):
            cluster_points = X[labels == i]
            if len(cluster_points) > 0:
                centroids[i] = np.mean(cluster_points, axis=0)
            else:
                centroids[i] = X[np.random.choice(X.shape[0])]
        return centroids

    def fit(self, X):
        self.centroids = self.initialize_centroids(X)
        prev_sse = 1e30
        next_sse = 0

        for iter in range(self.max_iterations):
            print("Iter: " + str(iter))
            old_centroids = np.copy(self.centroids)

            # Assign data points to clusters
            labels = self.assign_clusters(X, self.centroids)

            # Update centroids
            self.centroids = self.update_centroids(X, labels)

            error = np.linalg.norm(self.centroids - old_centroids)
            next_sse = self.calculate_sse(X, labels)

            if error < self.tol or next_sse > prev_sse or iter > 100:

                self.number_of_iterations = iter
                break
            prev_sse = next_sse

    def predict(self, X):
        distances = euclidean_distances(X, self.centroids)
        return np.argmin(distances, axis=1)

    def calculate_sse(self, X, labels):
        sse = 0
        for i in range(self.n_clusters):
            cluster_points = X[labels == i]
            centroid = self.centroids[i]
            sse += np.sum(np.linalg.norm(cluster_points - centroid, axis=1) ** 2)
        return sse

    def replace_with_majority_values(self, algo_label, true_label, n):
        algo_label_updated = np.copy(algo_label)  # Create a copy of algo_label

        for value in range(n):
            indices = np.where(algo_label == value)[0]
            values = true_label[indices]

            # Find the majority value
            majority_value, _ = mode(values)

            # Replace the corresponding values in algo_label_updated
            algo_label_updated[indices] = majority_value

        return algo_label_updated

######################################################################
# Test code
######################################################################

if __name__=="__main__":
    data = pd.read_csv("./data.csv")
    labels = pd.read_csv("./label.csv")

    labels_values = labels.values
    K = 10

    kmeans_euclidean = KMeans(n_clusters=K, distance_metric='euclidean')
    kmeans_cosine = KMeans(n_clusters=K, distance_metric='cosine')
    kmeans_jaccard = KMeans(n_clusters=K, distance_metric='jaccard')


    kmeans_euclidean.fit(data)
    kmeans_cosine.fit(data)
    kmeans_jaccard.fit(data)

    labels_euclidean = kmeans_euclidean.predict(data)
    labels_cosine = kmeans_cosine.predict(data)
    labels_jaccard = kmeans_jaccard.predict(data)

    sse_euclidean = kmeans_euclidean.calculate_sse(data, labels_euclidean)
    sse_cosine = kmeans_euclidean.calculate_sse(data, labels_cosine)
    sse_jaccard = kmeans_euclidean.calculate_sse(data, labels_jaccard)

    print("Euclidean Iterations:", kmeans_euclidean.number_of_iterations)
    print("Cosine Iterations:", kmeans_cosine.number_of_iterations)
    print("Jaccard Iterations:", kmeans_jaccard.number_of_iterations)
    print("\n")


    print("SSE Euclidean:", sse_euclidean)
    print("SSE Cosine:", sse_cosine)
    print("SSE Jaccard:", sse_jaccard)
    print("\n")

    majority_vote_labels_euclidean = kmeans_euclidean.replace_with_majority_values(labels_euclidean, labels_values, K)
    majority_vote_labels_cosine = kmeans_euclidean.replace_with_majority_values(labels_cosine, labels_values, K)
    majority_vote_labels_jaccard = kmeans_euclidean.replace_with_majority_values(labels_jaccard, labels_values, K)


    euclidean_accuracy = accuracy_score(labels_values, majority_vote_labels_euclidean)
    cosine_accuracy = accuracy_score(labels_values, majority_vote_labels_cosine)
    jaccard_accuracy = accuracy_score(labels_values, majority_vote_labels_jaccard)

    print("Euclidean Cluster Accuracy:", euclidean_accuracy)
    print("Cosine Cluster Accuracy:", cosine_accuracy)
    print("Jaccard Cluster Accuracy:", jaccard_accuracy)
    print("\n")
